import os
import time
import threading
import asyncio
from typing import List, Optional, Dict, Any
from contextlib import asynccontextmanager
from datetime import datetime

# API KÃ¼tÃ¼phaneleri
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# AI ve VeritabanÄ±
from supabase import create_client, Client
from dotenv import load_dotenv
import pdfplumber
import pytesseract
from PIL import Image
from io import BytesIO
from sentence_transformers import SentenceTransformer

# --- YENÄ° KATMANLAR ---
# KlasÃ¶r yapÄ±sÄ±nÄ±n python_service/layers/ altÄ±nda olduÄŸunu varsayÄ±yorum
from layers.guard import GuardLayer
from layers.router import RouterLayer, RouteType
from layers.rag import RAGLayer
from layers.web import WebSearchLayer

# .env yÃ¼kle
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))

# --- KONFIGÃœRASYON ---
SUPABASE_URL = os.getenv("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
MODEL_NAME = 'BAAI/bge-m3'

if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ Hata: .env eksik veya hatalÄ±.")
    # exit(1) # Hata olsa bile sunucuyu Ã§Ã¶kertmemek iÃ§in loglayÄ±p devam edebiliriz ama kritik.

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Global DeÄŸiÅŸkenler
embed_model = None
orchestrator = None # Yeni OrkestratÃ¶r SÄ±nÄ±fÄ±

# -----------------------------------------------------------------------------
# 1. ORKESTRASYON SINIFI (TÃœM BEYÄ°N BURADA)
# -----------------------------------------------------------------------------
class BabyLexitOrchestrator:
    def __init__(self):
        print("ğŸ§  OrkestratÃ¶r BaÅŸlatÄ±lÄ±yor...")
        self.guard = GuardLayer()
        self.router = RouterLayer()
        self.rag = RAGLayer()
        self.web = WebSearchLayer()

    async def process_query(self, user_query: str) -> Dict[str, Any]:
        """Sorguyu alÄ±r, RAG veya Web'e yÃ¶nlendirir ve cevabÄ± dÃ¶ner."""
        print(f"\n--- Sorgu Ä°ÅŸleniyor: {user_query} ---")
        
        # A. GÃ¼venlik
        guard_result = self.guard.check(user_query)
        if not guard_result.is_safe:
            return {"text": f"GÃ¼venlik UyarÄ±sÄ±: {guard_result.reason}", "sources": [], "route": "BLOCKED"}

        # B. Rota
        route = self.router.route(user_query)
        final_response = ""
        sources = []

        # C. Rota Uygulama
        if route == RouteType.LEGAL_DB:
            print("ğŸ“š RAG AranÄ±yor...")
            rag_result = self.rag.search(user_query)
            if rag_result:
                final_response = rag_result
                sources = ["BabyLexit Knowledge Base"]
            else:
                print("âš ï¸ DB'de bulunamadÄ±, Web'e gidiliyor...")
                route = RouteType.WEB_SEARCH # Fallback

        if route == RouteType.WEB_SEARCH:
            print("ğŸŒ Web TaranÄ±yor...")
            web_result = await self.web.run(user_query)
            if web_result.found:
                final_response = web_result.summary
                sources = web_result.source_links
            else:
                final_response = "GÃ¼venilir kaynaklarda bilgi bulunamadÄ±."

        elif route == RouteType.GENERAL:
            final_response = "Merhaba! Ben bir hukuk asistanÄ±yÄ±m. Size nasÄ±l yardÄ±mcÄ± olabilirim?"

        return {
            "text": final_response,
            "sources": sources,
            "route": route.value
        }

# -----------------------------------------------------------------------------
# 2. DOSYA Ä°ÅLEME VE EMBEDDING (SENÄ°N KODUNUN AYNI KALDIÄI KISIM)
# -----------------------------------------------------------------------------

# Model YÃ¼kleme (Sadece Ingestion iÃ§in local model kullanÄ±yoruz)
print(f"ğŸ“¥ Yerel AI Modeli YÃ¼kleniyor (CPU): {MODEL_NAME} ...")
try:
    embed_model = SentenceTransformer(MODEL_NAME, device='cpu')
    print("âœ… Yerel Embedding Modeli HazÄ±r!")
except Exception as e:
    print(f"âŒ Model HatasÄ±: {e}")

def get_local_embedding(text: str) -> List[float]:
    try:
        embedding = embed_model.encode(text, normalize_embeddings=True)
        return embedding.tolist()
    except Exception as e:
        print(f"Embedding HatasÄ±: {e}")
        return []

def chunk_text(text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        if chunk: chunks.append(chunk)
        start = end - overlap
    return chunks

def process_file_queue():
    """
    KullanÄ±cÄ±nÄ±n yÃ¼klediÄŸi dosyalarÄ± iÅŸler.
    (Bu fonksiyonu senin kodundan aynen korudum)
    """
    try:
        res = supabase.table('file_processing_queue').select("*").eq('status', 'pending').limit(1).execute()
        if not res.data: return False

        job = res.data[0]
        print(f"ğŸ“‚ Dosya Ä°ÅŸleniyor: {job['file_path']}")
        
        supabase.table('file_processing_queue').update({'status': 'processing'}).eq('id', job['id']).execute()
        
        # DosyayÄ± Ä°ndir
        file_bytes = supabase.storage.from_('raw_uploads').download(job['file_path'])
        
        text = ""
        ftype = job.get('file_type', '').lower() if job.get('file_type') else 'txt'
        
        # PDF / Text AyrÄ±mÄ±
        if 'pdf' in ftype:
            with pdfplumber.open(BytesIO(file_bytes)) as pdf:
                for page in pdf.pages:
                    text += (page.extract_text() or "") + "\n"
        else:
            text = file_bytes.decode('utf-8', errors='ignore')

        if len(text.strip()) < 10: raise ValueError("BoÅŸ iÃ§erik")

        # ParÃ§ala ve Kaydet
        chunks = chunk_text(text)
        docs = []
        for chunk in chunks:
            vec = get_local_embedding(chunk)
            if vec:
                docs.append({
                    'content': chunk,
                    'metadata': {'source': job['file_path'], 'user_id': job['user_id']},
                    'embedding': vec
                })
        
        if docs: supabase.table('documents').insert(docs).execute()
        
        supabase.table('file_processing_queue').update({'status': 'completed'}).eq('id', job['id']).execute()
        print(f"âœ… Dosya TamamlandÄ±: {job['file_path']}")
        return True

    except Exception as e:
        print(f"âŒ Dosya HatasÄ±: {e}")
        if 'job' in locals():
            supabase.table('file_processing_queue').update({'status': 'failed', 'error_message': str(e)}).eq('id', job['id']).execute()
        return False

# -----------------------------------------------------------------------------
# 3. SORU CEVAPLAMA WORKER (GÃœNCELLENEN KISIM)
# -----------------------------------------------------------------------------

def run_async(coro):
    """Senkron thread iÃ§inde Asenkron fonksiyon Ã§alÄ±ÅŸtÄ±rmak iÃ§in"""
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # EÄŸer zaten bir loop varsa (nadir) future kullan
            return asyncio.run_coroutine_threadsafe(coro, loop).result()
    except RuntimeError:
        pass
        
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    return loop.run_until_complete(coro)

def process_question_queue():
    """
    SÄ±radaki soruyu alÄ±r ve Orchestrator Ã¼zerinden geÃ§irir.
    (ArtÄ±k Web Search ve Guard yeteneklerine sahip!)
    """
    try:
        res = supabase.table('questions').select("*").eq('status', 'analyzing').limit(1).execute()
        if not res.data: return False

        question = res.data[0]
        q_text = f"{question['title']} \n {question['content']}"
        print(f"âš–ï¸ Soru Ä°ÅŸleniyor (Orchestrator): {question['title']}")

        if orchestrator:
            # --- YENÄ° MANTIK BURADA ---
            # Eskiden sadece embedding alÄ±p RAG yapÄ±yorduk.
            # Åimdi Orchestrator'a gÃ¶nderiyoruz, o karar veriyor (Web mi, DB mi?)
            result = run_async(orchestrator.process_query(q_text))
            
            answer_text = result["text"]
            sources_list = result["sources"] # KaynaklarÄ± da alabiliriz
        else:
            answer_text = "Sistem ÅŸu an baÅŸlatÄ±lÄ±yor, lÃ¼tfen bekleyin."

        # CevabÄ± Kaydet
        answer_data = {
            "question_id": question['id'],
            "user_id": question['user_id'], # veya bir Bot ID
            "content": answer_text,
            "is_ai_generated": True,
            "is_verified": False,
            "ai_score": 90 if "Web" in str(sources_list) else 85,
            "upvotes": 0,
            "downvotes": 0
        }
        
        supabase.table('answers').insert(answer_data).execute()
        supabase.table('questions').update({'status': 'answered'}).eq('id', question['id']).execute()
        
        print(f"âœ… Soru CevaplandÄ±: {answer_text[:50]}...")
        return True

    except Exception as e:
        print(f"âŒ Soru HatasÄ±: {e}")
        return False

# -----------------------------------------------------------------------------
# 4. ANA DÃ–NGÃœ VE API
# -----------------------------------------------------------------------------

def run_worker_loop():
    print("ğŸ‘· Worker Thread BaÅŸladÄ± (Dosya + AkÄ±llÄ± Soru Cevaplama)...")
    while True:
        try:
            did_file = process_file_queue()
            did_question = process_question_queue()

            if not did_file and not did_question:
                time.sleep(2)
                
        except Exception as e:
            print(f"Worker Loop Error: {e}")
            time.sleep(5)

@asynccontextmanager
async def lifespan(app: FastAPI):
    global orchestrator
    
    # TÃ¼m sistemi baÅŸlat
    orchestrator = BabyLexitOrchestrator()
    
    # Worker Thread BaÅŸlat
    worker_thread = threading.Thread(target=run_worker_loop, daemon=True)
    worker_thread.start()
    
    print("ğŸš€ BABYZLEXIT FULL ENGINE HAZIR!")
    yield

app = FastAPI(lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API Endpoint'i (Direct Chat iÃ§in)
class ChatRequest(BaseModel):
    query: str

@app.post("/api/chat")
async def chat_endpoint(req: ChatRequest):
    if not orchestrator:
        raise HTTPException(status_code=503, detail="Sistem baÅŸlatÄ±lÄ±yor")
    
    result = await orchestrator.process_query(req.query)
    return result

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)