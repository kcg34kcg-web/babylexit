import os
import time
import threading
import asyncio
from typing import List, Optional, Dict, Any
from contextlib import asynccontextmanager
from datetime import datetime

# API KÃ¼tÃ¼phaneleri
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# AI ve VeritabanÄ±
from supabase import create_client, Client
from dotenv import load_dotenv
import pdfplumber
import pytesseract
from PIL import Image
from io import BytesIO
from sentence_transformers import SentenceTransformer

# --- KATMANLAR ---
from layers.guard import GuardLayer
from layers.router import SemanticRouter
from layers.rag import InternalRAGAgent

# .env yÃ¼kle (Ãœst dizini kontrol et)
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))

# --- KONFIGÃœRASYON ---
SUPABASE_URL = os.getenv("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
MODEL_NAME = 'BAAI/bge-m3'

if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ Hata: .env eksik veya hatalÄ±.")
    exit(1)

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Global DeÄŸiÅŸkenler
embed_model = None
guard = None
router = None
rag_agent = None

# --- MODEL YÃœKLEME ---
print(f"ğŸ“¥ Yerel AI Modeli YÃ¼kleniyor (CPU): {MODEL_NAME} ...")
try:
    embed_model = SentenceTransformer(MODEL_NAME, device='cpu')
    print("âœ… Yerel Embedding Modeli HazÄ±r!")
except Exception as e:
    print(f"âŒ Model HatasÄ±: {e}")
    exit(1)

# --- YARDIMCI FONKSÄ°YONLAR ---
def get_local_embedding(text: str) -> List[float]:
    try:
        embedding = embed_model.encode(text, normalize_embeddings=True)
        return embedding.tolist()
    except Exception as e:
        print(f"Embedding HatasÄ±: {e}")
        return []

def chunk_text(text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        if chunk: chunks.append(chunk)
        start = end - overlap
    return chunks

# --- ASYNC WRAPPER ---
def run_async(coro):
    """Senkron thread iÃ§inde Asenkron fonksiyon Ã§alÄ±ÅŸtÄ±rmak iÃ§in"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    return loop.run_until_complete(coro)

# --- Ä°ÅÃ‡Ä° 1: DOSYA Ä°ÅLEME ---
def process_file_queue():
    try:
        res = supabase.table('file_processing_queue').select("*").eq('status', 'pending').limit(1).execute()
        if not res.data: return False

        job = res.data[0]
        print(f"ğŸ“‚ Dosya Ä°ÅŸleniyor: {job['file_path']}")
        
        supabase.table('file_processing_queue').update({'status': 'processing'}).eq('id', job['id']).execute()
        
        # DosyayÄ± Ä°ndir
        file_bytes = supabase.storage.from_('raw_uploads').download(job['file_path'])
        
        text = ""
        ftype = job.get('file_type', '').lower() if job.get('file_type') else 'txt'
        
        if 'pdf' in ftype:
            with pdfplumber.open(BytesIO(file_bytes)) as pdf:
                for page in pdf.pages:
                    text += (page.extract_text() or "") + "\n"
        else:
            text = file_bytes.decode('utf-8', errors='ignore')

        if len(text.strip()) < 10: raise ValueError("BoÅŸ iÃ§erik")

        # ParÃ§ala ve Kaydet
        chunks = chunk_text(text)
        docs = []
        for chunk in chunks:
            vec = get_local_embedding(chunk)
            if vec:
                docs.append({
                    'content': chunk,
                    'metadata': {'source': job['file_path'], 'user_id': job['user_id']},
                    'embedding': vec
                })
        
        if docs: supabase.table('documents').insert(docs).execute()
        
        supabase.table('file_processing_queue').update({'status': 'completed'}).eq('id', job['id']).execute()
        print(f"âœ… Dosya TamamlandÄ±: {job['file_path']}")
        return True

    except Exception as e:
        print(f"âŒ Dosya HatasÄ±: {e}")
        if 'job' in locals():
            supabase.table('file_processing_queue').update({'status': 'failed', 'error_message': str(e)}).eq('id', job['id']).execute()
        return False

# --- Ä°ÅÃ‡Ä° 2: SORU CEVAPLAMA (YENÄ° EKLENEN KISIM) ---
def process_question_queue():
    try:
        # 1. 'analyzing' durumundaki sorularÄ± bul
        res = supabase.table('questions').select("*").eq('status', 'analyzing').limit(1).execute()
        if not res.data: return False

        question = res.data[0]
        q_text = f"{question['title']} \n {question['content']}"
        print(f"âš–ï¸ Soru Analiz Ediliyor: {question['title']}")

        # 2. Embedding Al
        vec = get_local_embedding(q_text)
        
        # 3. RAG Agent'a Sor (Async iÅŸlemi Sync iÃ§inde Ã§alÄ±ÅŸtÄ±r)
        # Not: Global rag_agent lifespan ile baÅŸlatÄ±ldÄ±ÄŸÄ± iÃ§in burada doÄŸrudan eriÅŸilebilir
        if rag_agent:
            result = run_async(rag_agent.process(q_text, vec))
            answer_text = result["answer"]
        else:
            answer_text = "Sistem ÅŸu an hukuk modÃ¼lÃ¼ne eriÅŸemiyor."

        # 4. CevabÄ± 'answers' Tablosuna Ekle
        answer_data = {
            "question_id": question['id'],
            "user_id": question['user_id'], # CevabÄ± soruyu soran kiÅŸinin adÄ±na deÄŸil, AI adÄ±na eklemek gerekebilir ama ÅŸema gereÄŸi user_id zorunluysa soran kiÅŸiyi veya AI bot ID'sini kullanÄ±n.
            "content": answer_text,
            "is_ai_generated": True,
            "is_verified": False,
            "ai_score": 85,
            "upvotes": 0,
            "downvotes": 0
        }
        
        # EÄŸer sistemde bir 'AI Bot' kullanÄ±cÄ±sÄ± varsa onun ID'sini kullanmak daha iyi olur.
        # Yoksa soruyu soran kiÅŸiye atÄ±yoruz (geÃ§ici Ã§Ã¶zÃ¼m)
        supabase.table('answers').insert(answer_data).execute()

        # 5. Sorunun Durumunu GÃ¼ncelle
        supabase.table('questions').update({'status': 'answered'}).eq('id', question['id']).execute()
        
        print(f"âœ… Soru CevaplandÄ± ve DB'ye YazÄ±ldÄ±.")
        return True

    except Exception as e:
        print(f"âŒ Soru Cevaplama HatasÄ±: {e}")
        # Hata durumunda loop'a girmemesi iÃ§in durumu deÄŸiÅŸtirelim veya loglayalÄ±m
        # supabase.table('questions').update({'status': 'failed'}).eq('id', question['id']).execute()
        return False

# --- ANA DÃ–NGÃœ ---
def run_worker_loop():
    print("ğŸ‘· Worker Thread (Dosya + Soru) BaÅŸladÄ±...")
    while True:
        try:
            # Ã–nce dosya var mÄ± bak
            did_file = process_file_queue()
            
            # Sonra soru var mÄ± bak
            did_question = process_question_queue()

            # Ä°kisi de yoksa bekle
            if not did_file and not did_question:
                time.sleep(2)
                
        except Exception as e:
            print(f"Worker Loop Error: {e}")
            time.sleep(5)

# --- LIFESPAN ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global guard, router, rag_agent
    
    print("ğŸ›¡ï¸ ModÃ¼ller BaÅŸlatÄ±lÄ±yor...")
    guard = GuardLayer()
    router = SemanticRouter()
    rag_agent = InternalRAGAgent(supabase)
    
    # Worker Thread BaÅŸlat
    worker_thread = threading.Thread(target=run_worker_loop, daemon=True)
    worker_thread.start()
    
    print("ğŸš€ BABYZLEXIT BACKEND & WORKER HAZIR!")
    yield

app = FastAPI(lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class RouteRequest(BaseModel):
    query: str

@app.post("/route")
async def route_query(req: RouteRequest):
    # API Ã¼zerinden de cevap verebilmek iÃ§in (Chat ekranÄ± vs.)
    vec = get_local_embedding(req.query)
    result = await rag_agent.process(req.query, vec)
    return {"cached_response": result["answer"]}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)