import os
import json
import asyncio
import logging
from typing import List, Dict, Any, Optional, Callable

import google.generativeai as genai
from supabase import Client
from flashrank import Ranker, RerankRequest # pip install flashrank

# Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Gemini KonfigÃ¼rasyonu ---
MODEL_NAME = "gemini-1.5-flash" # json_mode desteÄŸi iÃ§in 1.5-flash daha kararlÄ± Ã§alÄ±ÅŸÄ±r

class InternalRAGAgent:
    def __init__(self, supabase_client: Client, embedding_fn: Callable[[str], List[float]]):
        """
        :param supabase_client: Supabase baÄŸlantÄ±sÄ±
        :param embedding_fn: Main.py'dan gelen yerel embedding fonksiyonu (BGE-M3)
        """
        self.supabase = supabase_client
        self.embedding_fn = embedding_fn # <-- KRÄ°TÄ°K: Embedding yeteneÄŸi kazandÄ±rÄ±ldÄ±
        self.api_key = os.getenv("GEMINI_API_KEY")
        
        if self.api_key:
            genai.configure(api_key=self.api_key)
            
            # 1. Avukat Karakteri (CevaplayÄ±cÄ±)
            self.answer_model = genai.GenerativeModel(
                model_name=MODEL_NAME,
                system_instruction="""
                Sen Babylexit'in KÄ±demli Hukuk DanÄ±ÅŸmanÄ±sÄ±n.
                GÃ¶revin: Sana verilen 'BELGE BAÄLAMI'nÄ± kullanarak kullanÄ±cÄ± sorusunu yanÄ±tlamak.
                Kurallar:
                1. Sadece verilen baÄŸlamdaki bilgileri kullan. Bilgi yoksa uydurma.
                2. CevaplarÄ±n profesyonel ve hukuki terminolojiye uygun olsun.
                3. Kaynak ismini (dosya adÄ±) cevabÄ±n sonunda belirt.
                """
            )

            # 2. AraÃ§ Modeli (Sorgu GeniÅŸletici - JSON Mode)
            self.tool_model = genai.GenerativeModel(
                model_name=MODEL_NAME,
                generation_config={"response_mime_type": "application/json"}
            )
        
        # 3. FlashRank (Reranker) - BaÅŸlangÄ±Ã§ta yÃ¼klenir
        print("âš–ï¸ RAG: FlashRank Reranker yÃ¼kleniyor...")
        self.ranker = Ranker(model_name="ms-marco-TinyBERT-L-2-v2")

    async def _expand_query(self, query: str) -> List[str]:
        """Gemini ile soruyu Ã§eÅŸitlendirir."""
        prompt = f"""
        KullanÄ±cÄ± hukuk sorusu sordu: "{query}"
        VeritabanÄ± aramasÄ± iÃ§in 3 alternatif arama terimi Ã¼ret.
        SADECE JSON listesi dÃ¶n: ["terim1", "terim2", "terim3"]
        """
        try:
            resp = await self.tool_model.generate_content_async(prompt)
            return json.loads(resp.text)
        except Exception as e:
            logger.error(f"Query Expansion HatasÄ±: {e}")
            return [query]

    async def retrieve_documents(self, embedding: List[float], limit: int = 10) -> List[Dict]:
        """Tek bir embedding iÃ§in Supabase aramasÄ±."""
        try:
            response = self.supabase.rpc(
                "match_documents",
                {
                    "query_embedding": embedding,
                    "match_threshold": 0.30, # GeliÅŸmiÅŸ aramada threshold'u dÃ¼ÅŸÃ¼rÃ¼p Reranker'a gÃ¼veniyoruz
                    "match_count": limit
                }
            ).execute()
            return response.data if response.data else []
        except Exception as e:
            logger.error(f"DB Retrieval HatasÄ±: {e}")
            return []

    async def generate_answer(self, query: str, context_docs: List[Dict]) -> Dict[str, Any]:
        """BaÄŸlamÄ± kullanarak cevap Ã¼retir."""
        if not context_docs:
            return {
                "answer": "Veri tabanÄ±mda bu konuyla ilgili yeterli hukuki dayanak bulamadÄ±m. Genel hukuk kurallarÄ± Ã§erÃ§evesinde yardÄ±mcÄ± olmamÄ± ister misiniz?",
                "sources": []
            }

        context_text = ""
        sources = []
        for doc in context_docs:
            meta = doc.get('metadata') or {}
            # Metadata bazen string gelebilir, kontrol et
            if isinstance(meta, str):
                try: meta = json.loads(meta)
                except: meta = {}
                
            source_name = meta.get('source', 'Bilinmeyen Belge')
            context_text += f"---\n[KAYNAK: {source_name}]\nÄ°Ã‡ERÄ°K: {doc.get('content')}\n"
            if source_name not in sources:
                sources.append(source_name)

        prompt = f"BELGE BAÄLAMI:\n{context_text}\n\nKULLANICI SORUSU:\n{query}\n\nLÃ¼tfen yanÄ±tla."

        try:
            response = await self.answer_model.generate_content_async(prompt)
            return {"answer": response.text, "sources": sources}
        except Exception as e:
            return {"answer": "Cevap Ã¼retilirken hata oluÅŸtu.", "sources": []}

    async def process(self, query: str, initial_embedding: List[float]) -> Dict[str, Any]:
        """
        KADEMELÄ° ARAMA (TIERED SEARCH):
        AdÄ±m 1: HÄ±zlÄ± Arama (Mevcut Embedding ile)
        AdÄ±m 2: (Gerekirse) GeliÅŸmiÅŸ Arama (Expansion + Reranking)
        """
        print(f"âš–ï¸ RAG BaÅŸlÄ±yor: '{query}'")

        # --- AÅAMA 1: HÄ±zlÄ± Kontrol ---
        docs = await self.retrieve_documents(initial_embedding, limit=5)
        
        # Karar MekanizmasÄ±: En iyi sonuÃ§ 0.75'ten dÃ¼ÅŸÃ¼kse GeliÅŸmiÅŸ Arama'ya geÃ§
        # Not: Supabase RPC genellikle similarity skoru dÃ¶ner.
        best_score = docs[0]['similarity'] if docs and 'similarity' in docs[0] else 0
        print(f"ğŸ“Š Ä°lk Arama En Ä°yi Skor: {best_score}")

        if best_score > 0.75:
            print("âœ… HÄ±zlÄ± arama yeterli bulundu.")
            return await self.generate_answer(query, docs)

        # --- AÅAMA 2: Derinlemesine AraÅŸtÄ±rma ---
        print("âš ï¸ Skor dÃ¼ÅŸÃ¼k, GeliÅŸmiÅŸ Arama (Tier 2) baÅŸlatÄ±lÄ±yor...")
        
        # 1. GeniÅŸlet
        variations = await self._expand_query(query)
        search_queries = [query] + variations
        print(f"ğŸ” Varyasyonlar: {variations}")

        # 2. Paralel Embedding & Arama
        # Not: embedding_fn main.py'da CPU'da Ã§alÄ±ÅŸÄ±yor, bloklamamasÄ± iÃ§in to_thread
        all_docs = []
        
        for q in search_queries:
            # Main.py'dan gelen fonksiyonu kullan
            vec = await asyncio.to_thread(self.embedding_fn, q)
            if vec:
                res = await self.retrieve_documents(vec, limit=10)
                all_docs.extend(res)

        # 3. TekilleÅŸtirme (Deduplication)
        unique_docs = {d['id']: d for d in all_docs}.values()
        doc_list = list(unique_docs)
        
        if not doc_list:
            return await self.generate_answer(query, [])

        # 4. Reranking (Yeniden SÄ±ralama)
        passages = [
            {"id": str(d['id']), "text": d['content'], "meta": d.get('metadata')} 
            for d in doc_list
        ]
        
        try:
            rerank_req = RerankRequest(query=query, passages=passages)
            ranked = await asyncio.to_thread(self.ranker.rank, rerank_req)
            
            # En iyi 5'i al (Skor > 0.60 filtresi eklenebilir)
            top_docs_data = [r for r in ranked if r['score'] > 0.60][:5]
            
            # Orijinal formata geri dÃ¶n
            final_docs = []
            for r in top_docs_data:
                final_docs.append({
                    "content": r['text'],
                    "metadata": r.get('meta')
                })
            print(f"ğŸ† Rerank SonrasÄ± SeÃ§ilen: {len(final_docs)} belge")
            
        except Exception as e:
            logger.error(f"Rerank hatasÄ±: {e}")
            final_docs = doc_list[:5]

        return await self.generate_answer(query, final_docs)