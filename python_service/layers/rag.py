import os
import json
import asyncio
from typing import List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field
import google.generativeai as genai
from supabase import create_client, Client
from flashrank import Ranker, RerankRequest

# --- AYARLAR ---
# 0 TL Stratejisi: Google Search'i sadece Ã§ok gerektiÄŸinde kullan.
# EÄŸer API kotan biterse burayÄ± False yap, sistem sadece veritabanÄ±ndan Ã§alÄ±ÅŸsÄ±n.
ENABLE_WEB_SEARCH = True 

# Resmi Kaynaklar (Web aramasÄ± yaparsa buraya odaklansÄ±n)
TRUSTED_LEGAL_SITES = [
    "resmigazete.gov.tr", "mevzuat.gov.tr", "tbmm.gov.tr", 
    "anayasa.gov.tr", "danistay.gov.tr", "yargitay.gov.tr"
]

MODEL_NAME = "gemini-2.0-flash" 
EMBEDDING_MODEL = "models/text-embedding-004" # DÄ°KKAT: Bu model 768 boyutludur.

# --- Veri Modelleri ---

class RagResult(BaseModel):
    found: bool
    source_type: str = Field(description="'internal' veya 'external'")
    context_str: str
    sources: List[str]
    chunks: List[Dict[str, Any]]

class QueryIntent(BaseModel):
    category: Literal["FACTUAL", "INTERNAL"]
    reasoning: str

# --- RAG KatmanÄ± ---

class RagLayer:
    def __init__(self):
        self.api_key = os.getenv("GOOGLE_API_KEY")
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY eksik!")
        genai.configure(api_key=self.api_key)
        
        # 1. Router & Chat Modeli (HÄ±zlÄ± ve Ucuz)
        self.llm = genai.GenerativeModel(
            MODEL_NAME,
            generation_config={"response_mime_type": "application/json"}
        )
        
        # 2. Web Arama Modeli (Sadece ihtiyaÃ§ anÄ±nda yÃ¼klenir)
        if ENABLE_WEB_SEARCH:
            self.web_model = genai.GenerativeModel(
                MODEL_NAME,
                tools=[{'google_search': {}}]
            )

        # 3. Supabase BaÄŸlantÄ±sÄ±
        self.supabase_url = os.getenv("SUPABASE_URL")
        self.supabase_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
        if not self.supabase_url:
            raise ValueError("SUPABASE Credentials eksik!")
        self.supabase: Client = create_client(self.supabase_url, self.supabase_key)

        # 4. Reranker (Yerel ve Bedava)
        print("âš¡ FlashRank (CPU) yÃ¼kleniyor...")
        self.ranker = Ranker(model_name="ms-marco-TinyBERT-L-2-v2", cache_dir="./.flashrank_cache")

    async def _get_embedding(self, text: str) -> List[float]:
        """
        Google Embedding (004) kullanÄ±r. 
        UYARI: Ã‡Ä±ktÄ± 768 boyutludur. Supabase'deki kolonun vector(768) olmasÄ± ÅARTTIR.
        """
        loop = asyncio.get_running_loop()
        try:
            result = await loop.run_in_executor(
                None, 
                lambda: genai.embed_content(
                    model=EMBEDDING_MODEL,
                    content=text,
                    task_type="retrieval_query"
                )
            )
            return result['embedding']
        except Exception as e:
            print(f"âš ï¸ Embedding HatasÄ±: {e}")
            return []

    async def _classify_intent(self, query: str) -> QueryIntent:
        """Sorguyu basitÃ§e ikiye ayÄ±rÄ±r: Ä°Ã§eri mi bakayÄ±m, dÄ±ÅŸarÄ± mÄ±?"""
        prompt = f"""
        Bu hukuk asistanÄ± iÃ§in gelen sorguyu analiz et: "{query}"
        
        Ä°ki seÃ§enek var:
        1. "INTERNAL": KullanÄ±cÄ±nÄ±n davasÄ±, dilekÃ§esi, Ã¶zel dosyalarÄ± veya karmaÅŸÄ±k hukuk analizi. (VarsayÄ±lan budur)
        2. "FACTUAL": Genel geÃ§er bilgi sorusu (Ã–rn: "Hava nasÄ±l?", "Dolar kaÃ§?", "BugÃ¼n tatil mi?").
        
        CevabÄ± JSON ver: {{ "category": "...", "reasoning": "..." }}
        """
        try:
            resp = await self.llm.generate_content_async(prompt)
            return QueryIntent.model_validate_json(resp.text)
        except:
            return QueryIntent(category="INTERNAL", reasoning="Fail-safe")

    async def _search_supabase(self, query: str) -> List[Dict]:
        """VeritabanÄ±nda vektÃ¶r aramasÄ± yapar."""
        vector = await self._get_embedding(query)
        if not vector: return []
        
        try:
            # Supabase RPC
            # Not: match_documents fonksiyonunun vector(768) kabul ettiÄŸinden emin ol.
            res = self.supabase.rpc('match_documents', {
                'query_embedding': vector,
                'match_threshold': 0.5, 
                'match_count': 10
            }).execute()
            return res.data if res.data else []
        except Exception as e:
            print(f"âš ï¸ DB HatasÄ±: {e}")
            return []

    async def _web_fallback(self, query: str) -> RagResult:
        """Google AramasÄ± yapar (0 TL bÃ¼tÃ§e iÃ§in sadece zorunlu hallerde)"""
        if not ENABLE_WEB_SEARCH:
            return RagResult(found=False, source_type="none", context_str="", sources=[], chunks=[])
            
        print(f"ğŸŒ Web AramasÄ± YapÄ±lÄ±yor: {query}")
        try:
            # Sadece gÃ¼venilir siteleri ekle (Prompt Engineering ile maliyetsiz filtre)
            sites = " OR ".join([f"site:{s}" for s in TRUSTED_LEGAL_SITES])
            prompt = f"Soruyu ÅŸu resmi kaynaklara gÃ¶re cevapla ({sites}): {query}"
            
            resp = await self.web_model.generate_content_async(prompt)
            
            # KaynaklarÄ± ayÄ±kla
            sources = []
            if resp.candidates and resp.candidates[0].grounding_metadata:
                for chunk in resp.candidates[0].grounding_metadata.grounding_chunks:
                    if hasattr(chunk, 'web'):
                        sources.append(chunk.web.title or chunk.web.uri)

            return RagResult(
                found=True,
                source_type="external",
                context_str=resp.text,
                sources=list(set(sources)),
                chunks=[]
            )
        except Exception as e:
            print(f"âŒ Web Search KotasÄ±/HatasÄ±: {e}")
            return RagResult(found=False, source_type="error", context_str="", sources=[], chunks=[])

    async def process(self, query: str) -> RagResult:
        print(f"ğŸš€ Ä°ÅŸleniyor: {query}")
        
        # 1. Router: SaÃ§ma sorular iÃ§in veritabanÄ±nÄ± yorma
        intent = await self._classify_intent(query)
        if intent.category == "FACTUAL":
            print("ğŸ’¡ Genel bilgi sorusu tespit edildi.")
            return await self._web_fallback(query)

        # 2. VeritabanÄ± AramasÄ± (Internal)
        docs = await self._search_supabase(query)
        
        # 3. SonuÃ§ Yoksa -> Web'e Git (Fallback)
        if not docs:
            print("âš ï¸ VeritabanÄ±nda bulunamadÄ± -> Web'e gidiliyor.")
            return await self._web_fallback(query)

        # 4. Reranking (BulunanlarÄ± SÄ±rala)
        passages = [
            {"id": str(d['id']), "text": d.get('content', ''), "meta": d.get('metadata', {})} 
            for d in docs
        ]
        rerank_req = RerankRequest(query=query, passages=passages)
        ranked = self.ranker.rerank(rerank_req)
        
        # En iyi 5 sonuÃ§
        final = ranked[:5]

        # EÄŸer Rerank sonucu bile Ã§ok kÃ¶tÃ¼yse (Skor < 0.20), Web'e git
        if not final or final[0]['score'] < 0.20:
             print("âš ï¸ SonuÃ§lar yetersiz -> Web'e gidiliyor.")
             return await self._web_fallback(query)

        # 5. Internal Cevap HazÄ±rlÄ±ÄŸÄ±
        context = "\n---\n".join([f"Kaynak: {i['meta'].get('source')}\n{i['text']}" for i in final])
        
        return RagResult(
            found=True,
            source_type="internal",
            context_str=context,
            sources=[i['meta'].get('source') for i in final],
            chunks=final
        )

# Test BloÄŸu
if __name__ == "__main__":
    async def main():
        rag = RagLayer()
        # Test: VeritabanÄ±nda olmayan bir ÅŸey soralÄ±m
        res = await rag.process("Ä°stanbul bugÃ¼n kaÃ§ derece?")
        print(f"Kaynak: {res.source_type}")
        print(res.context_str[:200])

    asyncio.run(main())